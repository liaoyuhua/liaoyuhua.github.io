<!DOCTYPE html>
<html><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A master of Statistics at University of Edinburgh">
    <meta name="keywords" content="hugo blog">
    <link rel="stylesheet" href=https://liaoyuhua.github.io/css/syntax.css>
    <link rel="stylesheet" href=https://liaoyuhua.github.io/css/style.css>
    <script src="https://kit.fontawesome.com/1b7478c139.js" crossorigin="anonymous"></script>
    <title>Yuhua&#39;s blog</title>
  </head><body><aside id="sidenav">
    <header>
    
        <a href=https://liaoyuhua.github.io/><img src="https://liaoyuhua.github.io/avatar.png" alt="avatar"></a>
        
    

    <a id="branding" href=https://liaoyuhua.github.io/>
        
            Yuhua&#39;s blog
        
    </a>
    </header>

    <nav>
        
            		
            <a href="https://liaoyuhua.github.io/"
                
            >
                <i class='fa fa-home fa-fw'></i>
                <span>Home</span>
            </a>
        
            		
            <a href="https://liaoyuhua.github.io/post/"
                
            >
                <i class='fa fa-list fa-fw'></i>
                <span>Posts</span>
            </a>
        
            		
            <a href="https://liaoyuhua.github.io/tags/"
                
            >
                <i class='fa fa-tags fa-fw'></i>
                <span>Tags</span>
            </a>
        
            		
            <a href="https://github.com/liaoyuhua"
                
                    target="_blank"
                
            >
                <i class="fab fa-github fa-ms"></i>
                <span>github</span>
            </a>
        
            		
            <a href="mailto:liaoyuhua95@gmail.com"
                
            >
                <i class="far fa-envelope"></i>
                <span>Email</span>
            </a>
        
    </nav>
</aside>
<main id="main">
            <a href="javascript:void(0)" id="closebtn" onclick="navToggle()"><i class="fas fa-bars fa-lg"></i></a>
            <div class="content">
    
    <h1 id="title">逻辑回归</h1>
    
      
    
    <h4 id="从分类问题说起">从分类问题说起</h4>

<p>既然线性回归可以用来拟合连续型的标签，那么可不可以用来拟合离散型的标签呢？</p>

<p>为了方便，我们考虑一维的情况，也就是说横坐标是输入特征<span  class="math">\(x\)</span>，纵坐标是标签<span  class="math">\(y\)</span>：</p>

<p><img src="C:\Users\1ia0\Downloads\linearregression.jpg" alt="linearregression" style="zoom: 35%;" /></p>

<p>这个示例很好地展示了，普通线性回归模型如果用于分类问题，会出现些什么问题，从另外的角度来讲，逻辑回归的提出正是用来克服普通线性回归这些问题的。</p>

<ol>
<li>线性回归虽然返回的是连续型值，但是不符合概率特性。</li>
</ol>

<p>所谓的概率<span  class="math">\(P(x)\)</span>，就是从样本空间到实数域的映射关系，且这个映射关系要满足一些条件，比如$P(x)$$要非负、不大于1等等。然而从上面的图可以发现，普通线性回归的输出值是不满足这些条件的。比如，远离样本稠密的区域的样本点会返回小于0或者大于1的值。</p>

<ol start="2">
<li>在实数域上对于样本点的敏感性一致</li>
</ol>

<p><img src="C:\Users\1ia0\Downloads\lr2.jpg" alt="lr2" style="zoom:30%;" /></p>

<p>这个示例展示了不同区域的样本点对于普通线性回归的分类效果的影响。如果样本线性可分，那么应该存在一个明确的类别分界点（一维条件下），如果样本点远离该分界点，那么线性回归为了平方误差最小，就会向远离类别分界点的样本偏移，导致阈值设定困难。因此，理想中的分类器应该在边界处尽可能变动明显，远离分界的区域尽可能惰性。</p>

<p><img src="C:\Users\1ia0\Downloads\lr.jpg" alt="lr" style="zoom:32%;" /></p>

<h4 id="基于sigmoid函数的改进">基于sigmoid函数的改进</h4>

<p>sigmoid函数实际是一类函数的统称：具有S形的函数。logistic函数是其中一种：<span  class="math">\(f(x) = \frac{1}{1 + e^{-x}}\)</span></p>

<p>从数学特征来分析：</p>

<p><span  class="math">\(\frac{d^2f(x)}{dx^2}=2\frac{e^{-2x}}{(1+e^{-x})^{3}}-\frac{e^{-x}}{(1+e^{-x})^{2}}=\frac{e^{-x}}{(1+e^{-x})^{2}}(2\frac{e^{-x}}{1+e^{-x}}-1)\)</span>：二阶导数当<span  class="math">\(x=0\)</span>时为<span  class="math">\(0\)</span>，当<span  class="math">\(x<0\)</span>时为正，当<span  class="math">\(x>0\)</span>时为负（<span  class="math">\(\frac{e^{-x}}{1+e^{-x}}=\frac{1}{1+e^x}\)</span>，和<span  class="math">\(\frac{1}{2}\)</span>比较大小）。</p>

<p><span  class="math">\(\frac{df(x)}{dx}=\frac{e^{-x}}{(1+e^{-x})^2}\)</span>：一阶导数单调为正，且在0邻域上升速度最快。且当<span  class="math">\(x\)</span>趋近于正无穷或负无穷时，一阶导数近似等于0。</p>

<p><span  class="math">\[\underset{x=正无穷}{lim}f(x)=1\]</span></p>

<p><span  class="math">\[\underset{x=负无穷}{lim}f(x)=0\]</span></p>

<p>函数图像：</p>

<p><img src="C:\Users\1ia0\Downloads\logistic-function-1.png" alt="logistic-function-1" style="zoom:20%;" /></p>

<p>因此，这是一个可导的、基本解决了普通线性回归的弊端的可用于分类的将样本特征空间映射到概率空间的函数。</p>

<h4 id="逻辑回归模型">逻辑回归模型</h4>

<p><strong>正式定义逻辑回归模型</strong></p>

<p>逻辑回归模型是如下的条件概率分布：</p>

<p><span  class="math">\[P(Y=1|x)=\frac{exp(w\times x+b)}{1+exp(w\times x+b)}\]</span></p>

<p><span  class="math">\[P(Y=0|x)=\frac{1}{1+exp(w\times x+b)}\]</span></p>

<p><strong>参数估计</strong></p>

<p>这里使用极大似然估计来进行参数估计。</p>

<p>设<span  class="math">\(P(Y=1|x)=\pi(x),P(Y=0|x)=1-\pi(x)\)</span>，那么似然函数是<span  class="math">\(Likelihood=\prod_{i=1}^{N}\pi(x_i)^{y_i}(1-\pi(x_i))^{1-y_i}\)</span></p>

<p>对数似然函数是<span  class="math">\(L(x)=log(likelihood)=\sum_{i=1}^{N}y_ilog(\pi(x_i))+(1-y_i)log(1-\pi(x))=\sum_{i=1}^{N}y_i\times wx-log(1+e^{wx})\)</span></p>

<p>然后求最优化问题：<span  class="math">\(\underset{w}{argmin}-\sum_{i=1}^{N}y_i\times wx-log(1+e^{wx})\)</span></p>

<p>这里采用梯度下降的方式求解。</p>

<h4 id="reference">Reference</h4>

<p>逻辑回归定义：《统计学习方法第二版》李航</p>

    
    <div class="nav-next-prev">
        <div class="nav-prev">
            
                <a href="https://liaoyuhua.github.io/post/k-means/"><i class="fas fa-chevron-left"></i></a>
            
        </div>
        <a class="nav-top" href="#">top</i></a>
        <div class="nav-next">
            
                <a class="grayed-out" href="javascript:void()"><i class="fas fa-chevron-right"></i></a>
            
        </div>
    </div>
    

            </div><footer>
<div class="footer-content">


<p class="copyright meta">Copyright © 2020–2020, LIAO Yuhua; all rights reserved.</p>

</div>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script></main>
    </body>
    <script src=https://liaoyuhua.github.io/js/navbutton.js></script>
</html>
